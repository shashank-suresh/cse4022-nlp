{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "146e0654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.probability import ConditionalFreqDist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1637f68f",
   "metadata": {},
   "source": [
    "## Frequency Distribution of words in a text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6e8d195",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 14, 'of': 10, 'and': 6, 'Russia': 5, 'in': 4, 'a': 3, 'by': 3, 'to': 3, 'On': 2, 'February': 2, ...})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "On 24 February 2022, Russia invaded Ukraine in a major escalation of the Russo-Ukrainian War, which began in 2014. The invasion has likely resulted in tens of thousands of deaths on both sides. It has caused Europe's largest refugee crisis since World War II.[10][11] An estimated 8 million Ukrainians were displaced within their country by late May and 7.8 million fled the country by 8 November 2022,[12][13][14][15] while Russia, within five weeks of the invasion, experienced its greatest emigration since the 1917 October Revolution.[16]\n",
    "\n",
    "Following the 2014 Ukrainian Revolution, Russia annexed Crimea, and Russian-backed paramilitaries seized part of the Donbas region of south-eastern Ukraine, which consists of Luhansk and Donetsk oblasts, sparking a regional war.[17][18] In March 2021, Russia began a large military build-up along its border with Ukraine, eventually amassing up to 190,000 troops and their equipment. Despite the build-up, denials of plans to invade or attack Ukraine were issued by various Russian government officials up to the day before the invasion.[22] On 21 February 2022, Russia recognised the Donetsk People's Republic and the Luhansk People's Republic, two self-proclaimed breakaway quasi-states in the Donbas.[23] The next day, the Federation Council of Russia authorised the use of military force and Russian troops entered both territories.[24]\n",
    "\"\"\"\n",
    "\n",
    "fd = nltk.FreqDist(text.split())\n",
    "fd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef26c64f",
   "metadata": {},
   "source": [
    "## Conditional Frequency Distribution of words in a text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fc4b119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'both': 2, 'were': 2, 'War,': 1, 'tens': 1, 'late': 1, 'fled': 1, 'five': 1, '1917': 1, '2014': 1, 'part': 1, ...})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd = ConditionalFreqDist((len(word), word) for word in text.split())\n",
    "cfd[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b397e1e",
   "metadata": {},
   "source": [
    "# HW 1: To determine Frequency Distribution and Conditional Frequency Distribution of any one of the Presidential inaugural addresses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e133830",
   "metadata": {},
   "source": [
    "## Frequency Distribution of words in a text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7a3b1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import inaugural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7ec3205",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1789-Washington.txt',\n",
       " '1793-Washington.txt',\n",
       " '1797-Adams.txt',\n",
       " '1801-Jefferson.txt',\n",
       " '1805-Jefferson.txt',\n",
       " '1809-Madison.txt',\n",
       " '1813-Madison.txt',\n",
       " '1817-Monroe.txt',\n",
       " '1821-Monroe.txt',\n",
       " '1825-Adams.txt',\n",
       " '1829-Jackson.txt',\n",
       " '1833-Jackson.txt',\n",
       " '1837-VanBuren.txt',\n",
       " '1841-Harrison.txt',\n",
       " '1845-Polk.txt',\n",
       " '1849-Taylor.txt',\n",
       " '1853-Pierce.txt',\n",
       " '1857-Buchanan.txt',\n",
       " '1861-Lincoln.txt',\n",
       " '1865-Lincoln.txt',\n",
       " '1869-Grant.txt',\n",
       " '1873-Grant.txt',\n",
       " '1877-Hayes.txt',\n",
       " '1881-Garfield.txt',\n",
       " '1885-Cleveland.txt',\n",
       " '1889-Harrison.txt',\n",
       " '1893-Cleveland.txt',\n",
       " '1897-McKinley.txt',\n",
       " '1901-McKinley.txt',\n",
       " '1905-Roosevelt.txt',\n",
       " '1909-Taft.txt',\n",
       " '1913-Wilson.txt',\n",
       " '1917-Wilson.txt',\n",
       " '1921-Harding.txt',\n",
       " '1925-Coolidge.txt',\n",
       " '1929-Hoover.txt',\n",
       " '1933-Roosevelt.txt',\n",
       " '1937-Roosevelt.txt',\n",
       " '1941-Roosevelt.txt',\n",
       " '1945-Roosevelt.txt',\n",
       " '1949-Truman.txt',\n",
       " '1953-Eisenhower.txt',\n",
       " '1957-Eisenhower.txt',\n",
       " '1961-Kennedy.txt',\n",
       " '1965-Johnson.txt',\n",
       " '1969-Nixon.txt',\n",
       " '1973-Nixon.txt',\n",
       " '1977-Carter.txt',\n",
       " '1981-Reagan.txt',\n",
       " '1985-Reagan.txt',\n",
       " '1989-Bush.txt',\n",
       " '1993-Clinton.txt',\n",
       " '1997-Clinton.txt',\n",
       " '2001-Bush.txt',\n",
       " '2005-Bush.txt',\n",
       " '2009-Obama.txt',\n",
       " '2013-Obama.txt',\n",
       " '2017-Trump.txt',\n",
       " '2021-Biden.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inaugural.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a011202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 240, ',': 195, 'of': 146, 'to': 132, '.': 110, 'and': 101, 'be': 76, 'in': 72, 'that': 57, 'a': 53, ...})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = inaugural.words(fileids='1861-Lincoln.txt')\n",
    "fd = nltk.FreqDist(text)\n",
    "fd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa746a7",
   "metadata": {},
   "source": [
    "## Conditional Frequency Distribution of words in a text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68cb3db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import ConditionalFreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "214fcd74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'that': 57, 'will': 25, 'this': 23, 'with': 20, 'have': 20, 'from': 16, 'such': 15, 'upon': 15, 'them': 13, 'than': 13, ...})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfd = ConditionalFreqDist((len(word), word) for word in text)\n",
    "cfd[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdf1140",
   "metadata": {},
   "source": [
    "## Chinese Segmentation using Jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5091e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366856f4",
   "metadata": {},
   "source": [
    "Forward Matching Algorithm chooses the longest word from the start of the string and splits it. For example, take the string: thetabledownthere\n",
    "\n",
    "Forward Matching Algorithm will result in the following words: ['theta', 'bled', 'own', 'there']\n",
    "\n",
    "Backward Matching Algorithm works similar to the Forward Matching Algorithm except it starts working from the end of the string.\n",
    "\n",
    "It results in the following words: ['there', 'down', 'table', 'the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f9e1edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中文 维基 维基百 维基百科 百科 计划 搭 其他 12 种 主要 语言 维基 维基百 维基百科 百科 计划 同时 成立\n"
     ]
    }
   ],
   "source": [
    "seg = jieba.cut(\"中文维基百科计划搭其他12种主要语言维基百科计划同时成立\", cut_all=True) # Uses a greedy algorithm - Forward Matching Algorithm\n",
    "print(\" \".join(seg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd38b739",
   "metadata": {},
   "source": [
    "## Basic Text Processing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f621a841",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3609a1d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Become', 'an', 'expert', 'in', 'NLP']\n"
     ]
    }
   ],
   "source": [
    "sent = \"Become an expert in NLP\"\n",
    "words = nltk.word_tokenize(sent) # Works similar to .split(), splits based on a delimiter (default is space)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82fa1e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7th', 'Heaven', 'is', 'an', 'American', 'television', 'drama', 'series', 'created', 'by', 'executive', 'producer', 'Brenda', 'Hampton', ',', 'and', 'co-executive', 'produced', 'by', 'Aaron', 'Spelling', 'and', 'E.', 'Duke', 'Vincent', 'through', 'Spelling', 'Television', '.']\n",
      "[('7th', 'CD'), ('Heaven', 'NNP'), ('is', 'VBZ'), ('an', 'DT'), ('American', 'JJ'), ('television', 'NN'), ('drama', 'NN'), ('series', 'NN'), ('created', 'VBN'), ('by', 'IN'), ('executive', 'JJ'), ('producer', 'NN'), ('Brenda', 'NNP'), ('Hampton', 'NNP'), (',', ','), ('and', 'CC'), ('co-executive', 'JJ'), ('produced', 'VBN'), ('by', 'IN'), ('Aaron', 'NNP'), ('Spelling', 'NNP'), ('and', 'CC'), ('E.', 'NNP'), ('Duke', 'NNP'), ('Vincent', 'NNP'), ('through', 'IN'), ('Spelling', 'NNP'), ('Television', 'NNP'), ('.', '.')]\n",
      "------\n",
      "['[', '1', ']', 'The', 'series', 'revolves', 'around', 'a', 'family', 'headed', 'by', 'parents', 'Eric', 'Camden', '(', 'Stephen', 'Collins', ')', ',', 'a', 'Protestant', 'Reverend', ',', 'and', 'Annie', 'Camden', '(', 'Catherine', 'Hicks', ')', ',', 'a', 'homemaker', '.']\n",
      "[('[', 'RB'), ('1', 'CD'), (']', 'VBD'), ('The', 'DT'), ('series', 'NN'), ('revolves', 'VBZ'), ('around', 'IN'), ('a', 'DT'), ('family', 'NN'), ('headed', 'VBN'), ('by', 'IN'), ('parents', 'NNS'), ('Eric', 'NNP'), ('Camden', 'NNP'), ('(', '('), ('Stephen', 'NNP'), ('Collins', 'NNP'), (')', ')'), (',', ','), ('a', 'DT'), ('Protestant', 'NNP'), ('Reverend', 'NNP'), (',', ','), ('and', 'CC'), ('Annie', 'NNP'), ('Camden', 'NNP'), ('(', '('), ('Catherine', 'NNP'), ('Hicks', 'NNP'), (')', ')'), (',', ','), ('a', 'DT'), ('homemaker', 'NN'), ('.', '.')]\n",
      "------\n",
      "['Their', 'seven', 'children', 'are', 'Matt', '(', 'Barry', 'Watson', ')', ',', 'Mary', '(', 'Jessica', 'Biel', ')', ',', 'Lucy', '(', 'Beverley', 'Mitchell', ')', ',', 'Simon', '(', 'David', 'Gallagher', ')', ',', 'Ruthie', '(', 'Mackenzie', 'Rosman', ')', 'and', 'twins', 'Sam', 'and', 'David', '(', 'Nikolas', 'and', 'Lorenzo', 'Brino', ')', '.']\n",
      "[('Their', 'PRP$'), ('seven', 'CD'), ('children', 'NNS'), ('are', 'VBP'), ('Matt', 'NNP'), ('(', '('), ('Barry', 'NNP'), ('Watson', 'NNP'), (')', ')'), (',', ','), ('Mary', 'NNP'), ('(', '('), ('Jessica', 'NNP'), ('Biel', 'NNP'), (')', ')'), (',', ','), ('Lucy', 'NNP'), ('(', '('), ('Beverley', 'NNP'), ('Mitchell', 'NNP'), (')', ')'), (',', ','), ('Simon', 'NNP'), ('(', '('), ('David', 'NNP'), ('Gallagher', 'NNP'), (')', ')'), (',', ','), ('Ruthie', 'NNP'), ('(', '('), ('Mackenzie', 'NNP'), ('Rosman', 'NNP'), (')', ')'), ('and', 'CC'), ('twins', 'VBZ'), ('Sam', 'NNP'), ('and', 'CC'), ('David', 'NNP'), ('(', '('), ('Nikolas', 'NNP'), ('and', 'CC'), ('Lorenzo', 'NNP'), ('Brino', 'NNP'), (')', ')'), ('.', '.')]\n",
      "------\n"
     ]
    }
   ],
   "source": [
    "texts = [\"\"\"7th Heaven is an American television drama series created by executive producer Brenda Hampton, \n",
    "and co-executive produced by Aaron Spelling and E. Duke Vincent through Spelling Television.[1] \n",
    "The series revolves around a family headed by parents Eric Camden (Stephen Collins), a Protestant Reverend, \n",
    "and Annie Camden (Catherine Hicks), a homemaker. Their seven children are Matt (Barry Watson), Mary (Jessica Biel), \n",
    "Lucy (Beverley Mitchell), Simon (David Gallagher), Ruthie (Mackenzie Rosman) and twins Sam and David (Nikolas and Lorenzo \n",
    "Brino).\"\"\"\n",
    "]\n",
    "for text in texts:\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    for sentence in sentences:\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        \n",
    "        print(words)\n",
    "        tagged = nltk.pos_tag(words) # Tags each of the words in each of the sentences based on the Penn Treebank tag set\n",
    "        print(tagged)\n",
    "        print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fccdd97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
